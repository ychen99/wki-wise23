{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "053011f5-e2f4-4edb-9ca3-18b59de282b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi==2024.2.2 in /Users/wenhao/anaconda3/envs/wki-ws23/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in /Users/wenhao/anaconda3/envs/wki-ws23/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (3.3.2)\n",
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.2.0 Requires-Python >=3.9\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement contourpy==1.2.0 (from versions: 0.0.1, 0.0.2, 0.0.3, 0.0.4, 0.0.5, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5, 1.0.6, 1.0.7, 1.1.0, 1.1.1rc1, 1.1.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for contourpy==1.2.0\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22a3bbf-e3de-472d-bdd6-8f8971a5c17c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "from scipy import fft\n",
    "import numpy as np\n",
    "from wettbewerb import get_3montages, EEGDataset\n",
    "from scipy import signal as sig\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5f3b361-3f9c-4f83-880a-6d60a80e426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass_filter(_signal, lowcut, highcut, freq, order=4):\n",
    "    nyquist = 0.5 * freq\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    filtered_sig = filtfilt(b, a, _signal)\n",
    "    return filtered_sig\n",
    "\n",
    "\n",
    "def compute_band_power(sig, freq, freq_low, freq_high):\n",
    "    spectrum = fft.fft(sig)\n",
    "    frequencies = np.fft.fftfreq(len(sig), d=1/freq)\n",
    "    freq_range = (frequencies >= freq_low) & (frequencies <= freq_high)\n",
    "    power = np.sum(np.abs(spectrum[freq_range])**2) / len(freq_range)\n",
    "    return power\n",
    "    \n",
    "    \n",
    "def pre_processing(_channels, _data, fr):#, scaler):\n",
    "    _montage, _montage_data, _is_missing = get_3montages(_channels, _data)\n",
    "\n",
    "    amplitude_means = np.zeros(len(_montage))\n",
    "    mean_amplitude = []\n",
    "    amplitude_max = np.zeros(len(_montage))\n",
    "    max_amplitude = []\n",
    "    amplitude_std = np.zeros(len(_montage))\n",
    "    std_amplitude = []\n",
    "    \n",
    "    band_power = np.zeros(4)\n",
    "\n",
    "    for j, signal_name in enumerate(_montage):\n",
    "        signal = _montage_data[j]\n",
    "        signal_notch = mne.filter.notch_filter(x=signal, Fs=fr, freqs=np.array([50., 100.]), \n",
    "                                                n_jobs=2, verbose=False)\n",
    "        signal_filter = butter_bandpass_filter(_signal=signal, lowcut=0.5, \n",
    "                                                   highcut=70.0, freq=fr)\n",
    "\n",
    "        # Calculate FFT and mean amplitude\n",
    "        spectrum = fft.fft(signal_filter)\n",
    "        amplitude_means[j] = np.mean(np.abs(spectrum))\n",
    "        amplitude_max[j] = np.max(np.abs(spectrum))\n",
    "        amplitude_std[j] = np.std(np.abs(spectrum))\n",
    "\n",
    "        # Compute band power\n",
    "        band_power[0] += compute_band_power(signal_filter, fr, 0.5, 4)\n",
    "        band_power[1] += compute_band_power(signal_filter, fr, 4, 8)\n",
    "        band_power[2] += compute_band_power(signal_filter, fr, 8, 13)\n",
    "        band_power[3] += compute_band_power(signal_filter, fr, 13, 30)\n",
    "        \n",
    "    mean_amplitude.append(np.mean(amplitude_means))\n",
    "    mean_amplitude = np.array(mean_amplitude)\n",
    "    max_amplitude.append(np.mean(amplitude_max))\n",
    "    max_amplitude = np.array(max_amplitude)\n",
    "    std_amplitude.append(np.mean(amplitude_std))\n",
    "    std_amplitude = np.array(std_amplitude)\n",
    "    \n",
    "    band_power /= len(_montage)\n",
    "    features = np.concatenate((mean_amplitude, max_amplitude, std_amplitude, band_power), axis=0)\n",
    "    #features_reshaped = features.reshape(1, -1)\n",
    "    #feature_scaled = scaler.transform(features_reshaped)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af54cf0c-9be4-44e0-85c9-332bea2e7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_eeg_signals(eeg_signals, target_length, fs=256):\n",
    "    \"\"\"\n",
    "    对不同长度的EEG信号进行填充，使它们长度相同。\n",
    "    :param eeg_signals: 包含多个EEG信号的列表，每个信号可能长度不同。\n",
    "    :param target_length: 目标长度（秒），所有信号将被填充或截断至此长度。\n",
    "    :param fs: EEG数据的采样频率（Hz）。\n",
    "    :return: 填充后的EEG信号列表。\n",
    "    \"\"\"\n",
    "    padded_signals = []\n",
    "    target_samples = target_length * fs  # 将目标长度转换为样本数\n",
    "\n",
    "    for signal in eeg_signals:\n",
    "        if len(signal) < target_samples:\n",
    "            # 如果信号长度小于目标长度，则进行零填充\n",
    "            padded_signal = np.pad(signal, (0, target_samples - len(signal)), 'constant')\n",
    "        else:\n",
    "            # 如果信号长度大于或等于目标长度，则截断至目标长度\n",
    "            padded_signal = signal[:target_samples]\n",
    "        padded_signals.append(padded_signal)\n",
    "    padded_signals = np.array(padded_signals)\n",
    "    \n",
    "    return padded_signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71cf34c5-c800-443e-8a10-a12dec2113c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eeg_data():\n",
    "    \"\"\"\n",
    "    load eeg signal and do padding, feature extraction one by one\n",
    "    :return: all_window_features: features on each window of EEG signals, shape (6213,59,7), representing 6213 EEG data, each having 59 windows, each window 7 features\n",
    "    :return: all_window_labels: the correspoing label on each window of eeg signals. shape(6213,59)\n",
    "    :return: all_eeg_labels: the label of each. signal correspoing the the. number in REFERENCE.csv\n",
    "    \"\"\"\n",
    "    #initilize channels, data, sampling_frequencies, reference_system, all_eeg_labels\n",
    "    channels: List[List[str]] = []\n",
    "    data: List[np.ndarray] = []\n",
    "    sampling_frequencies: List[float] = []\n",
    "    reference_systems: List[str] = []\n",
    "    all_eeg_labels: List[Tuple[bool,float,float]] = []\n",
    "    \n",
    "    #List. to store features and labels on each window\n",
    "    all_window_features = []\n",
    "    all_window_labels = []\n",
    "    #define a standard scaler\n",
    "    scaler = StandardScaler()\n",
    "    dataset = EEGDataset(\"../shared_data/training\")\n",
    "    #initilize a np array to store the features\n",
    "    features = np.empty((0,59,7))\n",
    "    \n",
    "    for item in dataset:\n",
    "        _eeg_label = item[5] \n",
    "        all_eeg_labels.append(item[5])\n",
    "        _chann =item[1]\n",
    "        _eeg_signals=item[2]\n",
    "        _fs=item[3]\n",
    "        # pad each signal eeg signal to lenth 300 with its own sampling frequency\n",
    "        padded_signal = pad_eeg_signals(_eeg_signals, 300, _fs) \n",
    "        # scale the padded signal\n",
    "        padded_signal = scaler.fit_transform(padded_signal)\n",
    "        window_size = 10 # each window is 10 seconds\n",
    "        step_size = 5 # step size. if 5 seconds\n",
    "        \n",
    "        window_samples = window_size * _fs # transoform window size from time to number of samples\n",
    "        step_samples = step_size * _fs # transoform step size size from time to number of samples\n",
    "        # initialize list to store the result\n",
    "        all_windows=[]\n",
    "        window_features = []\n",
    "        window_labels = []\n",
    "        \n",
    "        for start_idx in range(0, padded_signal.shape[1] - window_samples + 1, step_samples):\n",
    "            onset_sample_point = int(_eeg_label[1] * _fs) # define the onset to sample point\n",
    "            offset_sample_point = int(_eeg_label[2] * _fs) if _eeg_label[2]<=300 else 300* _fs # define the offset to sample point\n",
    "            \n",
    "            window = padded_signal[:, start_idx:start_idx + window_samples] #window of padded signal\n",
    "            window_feature = pre_processing(_chann, window, _fs) # extract hidden. features of this window\n",
    "            # if the window is totally on the left of onset point or totally on the right of offset point,or the onset point is zero, label this window 0\n",
    "            if (start_idx < onset_sample_point and start_idx + window_samples < onset_sample_point) or (start_idx>offset_sample_point and start_idx + window_samples > offset_sample_point) or onset_sample_point== 0:\n",
    "                window_label = 0\n",
    "            else:\n",
    "                window_label = 1 #apart form the conditions, label the window 1\n",
    "            window_labels.append(window_label)\n",
    "            window_features.append(window_feature)\n",
    "            all_windows.append(window)\n",
    "        window_features = np.array(window_features)\n",
    "        window_labels = np.array(window_labels)\n",
    "        all_window_features.append(window_features)\n",
    "        all_window_labels.append(window_labels)\n",
    "    \n",
    "    all_window_features = np.array(all_window_features)\n",
    "    all_window_labels = np.array(all_window_labels)\n",
    "        \n",
    "    #features = np.vstack((features, new_feature))\n",
    "    return all_window_features, all_window_labels, all_eeg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9540efa1-095b-4ef4-9be5-861183fbe44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset of all features, shape (6213,59,7)\n",
    "#representing 6213 EEG data, each having 59 windows, each window 7 features\n",
    "all_window_features = np.load('all_window_features.npy') \n",
    "# all EEG data labels ,shape (6213,59),6213 EEG data, each of them has 59 labels of 0 or 1\n",
    "all_window_labels = np.load('all_window_labels.npy')\n",
    "# all EEG data labels, shape(6213,3), representing 6213 EEG data, each having 3 label, seizure-onset-offset\n",
    "eeg_labels = np.load('eeg_labels.npy')\n",
    "# label representing if the EEG signal is seizure\n",
    "seizure = [item[0] for item in eeg_labels]\n",
    "seizure = np.array(seizure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4a873e7-27b5-41c1-ac11-7754ab460522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6213, 3)\n",
      "(6213, 59, 7)\n",
      "(6213, 59)\n",
      "(6213,)\n"
     ]
    }
   ],
   "source": [
    "print(eeg_labels.shape)\n",
    "print(all_window_features.shape)\n",
    "print(all_window_labels.shape)\n",
    "print(seizure.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d0d0528-c7d9-47cd-840c-e5ec6fe0146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the first index of three continous window, whose label is 1\n",
    "def find_first_triple_one(sequence):\n",
    "    if len(sequence) < 3:  \n",
    "        return 0\n",
    "\n",
    "    window_sum = sequence[0] + sequence[1] + sequence[2]\n",
    "    if window_sum == 3:\n",
    "        return 0\n",
    "\n",
    "    for i in range(3, len(sequence)):\n",
    "        window_sum += sequence[i] - sequence[i-3] #add new element, delete the first one \n",
    "        if window_sum == 3:\n",
    "            return i - 2  # return the first index of these three windows\n",
    "\n",
    "    return 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b258e7a1-9489-460a-a289-9188131d62b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the features, so that all the windows are mixed together\n",
    "# label also\n",
    "reshaped_features = all_window_features.reshape(-1, 7)\n",
    "reshaped_labels = all_window_labels.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88abfd13-712e-4cce-a679-7c6f6663243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y1_train, Y1_test, Y2_train, Y2_test = train_test_split(all_window_features, eeg_labels, all_window_labels, test_size=0.2, random_state=42, stratify=seizure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c9917e-35ff-4f5d-b0cb-01aba5f0d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split of mixed window features and labels\n",
    "x_train, x_test, y_train, y_test = train_test_split(reshaped_features, reshaped_labels, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fee7cef-6ec8-4b1a-84a0-dadaa78187a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build random forest classifier\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# train RF with mixed window, cause in the following prediction part, we classify each window, instead of each eeg signal\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9dac87d-0584-4de8-bd6f-0c73ea78e30b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 35, 0, 0, 0, 0, 0, 0, 140, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 0, 155, 0, 0, 0, 0, 0, 30, 0, 0, 0, 90, 0, 0, 0, 0, 0, 0, 0, 0, 190, 105, 0, 0, 0, 0, 0, 0, 65, 0, 0, 0, 145, 0, 0, 0, 0, 270, 0, 0, 0, 0, 0, 0, 15, 0, 0, 0, 25, 0, 0, 60, 0, 0, 180, 0, 0, 0, 0, 0, 0, 0, 35, 0, 0, 0, 0, 20, 45, 0, 0, 0, 0, 20, 150, 0, 0, 0, 0, 0, 0, 80, 85, 185, 0, 0, 30, 15, 0, 0, 0, 0, 0, 0, 80, 0, 0, 115, 0, 20, 0, 0, 0, 80, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 200, 0, 0, 160, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 65, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 60, 0, 0, 0, 0, 0, 15, 0, 0, 0, 0, 0, 0, 60, 0, 0, 0, 100, 0, 45, 0, 0, 0, 90, 0, 0, 140, 0, 0, 0, 0, 0, 30, 15, 155, 0, 55, 0, 0, 25, 0, 0, 20, 0, 0, 0, 0, 0, 5, 0, 15, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 90, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 135, 0, 0, 0, 0, 235, 0, 25, 0, 50, 0, 0, 25, 25, 0, 0, 0, 0, 0, 0, 70, 0, 0, 0, 0, 0, 60, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 40, 0, 75, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 25, 0, 85, 265, 0, 50, 0, 0, 0, 0, 105, 0, 0, 0, 0, 10, 35, 0, 0, 70, 25, 45, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 85, 0, 0, 0, 20, 0, 0, 110, 15, 0, 0, 0, 0, 0, 0, 160, 0, 0, 0, 0, 0, 0, 135, 0, 0, 0, 0, 15, 0, 0, 20, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 275, 0, 150, 0, 0, 0, 0, 0, 0, 0, 80, 0, 0, 0, 0, 0, 0, 0, 235, 0, 0, 0, 0, 0, 130, 0, 0, 0, 0, 0, 0, 0, 60, 15, 0, 190, 0, 0, 25, 75, 65, 0, 0, 0, 0, 0, 0, 75, 0, 0, 0, 0, 120, 0, 0, 0, 245, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 20, 0, 140, 0, 0, 0, 0, 0, 0, 160, 0, 0, 0, 0, 110, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 0, 0, 0, 5, 10, 0, 5, 195, 0, 0, 45, 0, 0, 0, 0, 0, 0, 0, 0, 30, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 195, 0, 0, 50, 0, 0, 0, 0, 0, 95, 0, 0, 0, 0, 20, 0, 0, 0, 160, 0, 0, 60, 0, 0, 0, 0, 0, 15, 60, 0, 0, 5, 0, 0, 0, 0, 0, 0, 50, 0, 0, 0, 0, 0, 0, 0, 0, 0, 25, 0, 0, 0, 0, 120, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 210, 90, 0, 0, 0, 0, 0, 255, 0, 250, 0, 0, 0, 0, 0, 0, 0, 60, 0, 0, 5, 0, 0, 245, 35, 0, 270, 0, 0, 45, 60, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 250, 0, 0, 0, 0, 230, 0, 15, 15, 0, 0, 40, 0, 0, 245, 5, 0, 40, 45, 15, 0, 0, 0, 0, 25, 105, 0, 270, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 155, 0, 0, 0, 0, 0, 65, 0, 185, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 155, 0, 0, 0, 25, 0, 0, 0, 245, 35, 55, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 80, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 175, 0, 80, 0, 10, 35, 0, 0, 0, 0, 20, 0, 135, 0, 0, 10, 10, 0, 0, 125, 0, 115, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 30, 0, 0, 0, 0, 0, 10, 110, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 90, 30, 0, 10, 0, 0, 30, 160, 0, 0, 0, 0, 0, 0, 20, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 170, 0, 0, 0, 10, 0, 25, 0, 10, 0, 0, 0, 0, 240, 90, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50, 0, 0, 45, 0, 0, 0, 0, 0, 0, 30, 35, 0, 0, 100, 10, 0, 0, 0, 0, 0, 0, 0, 0, 50, 0, 0, 0, 0, 0, 145, 55, 0, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 230, 0, 0, 15, 25, 0, 0, 0, 40, 0, 65, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 40, 25, 0, 30, 10, 0, 40, 0, 0, 0, 0, 25, 15, 0, 20, 0, 0, 0, 145, 0, 0, 0, 110, 5, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 5, 0, 0, 0, 0, 0, 215, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 265, 0, 170, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 85, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 75, 15, 0, 0, 190, 0, 0, 0, 35, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 35, 0, 0, 0, 0, 0, 120, 0, 0, 0, 0, 230, 0, 25, 50, 55, 0, 0, 0, 0, 0, 40, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 20, 0, 0, 5, 0, 0, 40, 0, 0, 0, 0, 0, 15, 0, 0, 0, 0, 0, 0, 0, 80, 0, 55, 0, 0, 0, 0, 0, 115, 0, 0, 0, 0, 0, 0, 0, 0, 280, 0, 0, 270, 35, 0, 0, 0, 0, 30, 40, 0, 0, 0, 0, 0, 0, 45, 0, 0, 70, 0, 0, 0, 0, 65, 0, 0, 0, 0, 0, 0, 20, 0, 0, 25, 0, 0, 95, 0, 0, 0, 0, 0, 65, 0, 0, 0, 0, 0, 0, 0, 255, 20, 0, 0, 0, 0, 0, 55, 85, 0, 0, 0, 0, 0, 0, 25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 60, 0]\n"
     ]
    }
   ],
   "source": [
    "# determine the onset of each signal\n",
    "onset=[] \n",
    "for signal in X_test:\n",
    "    window_seizure=[] # store the label of each window in a single signal\n",
    "    for window in signal:\n",
    "        _prediction = rf.predict(window.reshape(1, -1)) # predict the label of each window \n",
    "        window_seizure.append(_prediction[0]) # store the label(0 or 1) \n",
    "        first_index = find_first_triple_one(window_seizure)# find the first index of 3 continous window\n",
    "    onset.append(first_index * 5) # step size is 5, onset is index * 5\n",
    "print(onset)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d6983b0-cc4d-4e91-9de3-f4192ebc62c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# determine the label of each signal\n",
    "# if the onset of this signal is not zero, the label is 1, instead, 0\n",
    "\n",
    "eeg_signal_label = []\n",
    "for item in onset:\n",
    "    if item>0:\n",
    "        eeg_signal_label.append(1)\n",
    "    else:\n",
    "        eeg_signal_label.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a6c82fc-18ab-4d45-8f77-cb17a6fe76f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[759   0]\n",
      " [215 269]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      1.00      0.88       759\n",
      "         1.0       1.00      0.56      0.71       484\n",
      "\n",
      "    accuracy                           0.83      1243\n",
      "   macro avg       0.89      0.78      0.80      1243\n",
      "weighted avg       0.87      0.83      0.81      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y1_test_label = [item[0] for item in Y1_test]\n",
    "# confusion matrix and report\n",
    "cm = confusion_matrix(Y1_test_label, eeg_signal_label)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "report = classification_report(Y1_test_label, eeg_signal_label)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b86a8c14-e606-4014-8e76-97a9f57448cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(rf, 'random_forest_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba14220-c646-4230-bf8d-b6c71e0c6be4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wki-ws23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
